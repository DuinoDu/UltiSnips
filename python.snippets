snippet tool
#!/usr/bin/env python
# -*- coding: utf-8 -*-

'''
python ${1:yourFunction}.py ${2:args}
'''
import os, sys

def $1(argv):
	${3:pass}

def main():
    import sys
	if len(sys.argv) != 2:
		print(__doc__)
		return
    $1(sys.argv)

if __name__ == "__main__":
	main()
endsnippet

snippet isdir
if not os.path.exists(${1:dirname}):
    os.makedirs($1)
endsnippet

snippet dump
with open('${2:file}', 'w') as fid:
	cPickle.dump(${1:var}, fid)
endsnippet
snippet load
with open('${1:file}', 'r') as fid:
	${2:var} = cPickle.load(fid)
endsnippet

snippet sh
(status, output) = commands.getstatusoutput('$1')
output = output.split('\n')
endsnippet

snippet printi
    sys.stdout.flush()
    sys.stdout.write('writing {}/{}\r'.format(i, len(files)))
    i += 1 # set i = 0 before looping
print '\nFinish!'
endsnippet

snippet prop
@property
def ${1:name}(self):
    return self._$1
endsnippet

snippet camera
cap = cv2.VideoCapture(0)
while True:
    ok, f = cap.read()
    if ok:    
        cv2.imshow("image", f)
    if cv2.waitKey(20) == 27:
        break
cv2.destroyAllWindows()
endsnippet

snippet esc
ch = cv2.waitKey(0) & 0xff
if ch == 27: #ord('q')
	break
endsnippet

snippet cv2rect
cv2.rectangle(${1:img}, (${2:x1}, ${3:y1}), (${4:x2}, ${5:y2}), (0, 255, 0), 2)
endsnippet

# mxnet
snippet conv
conv${1:1} = mx.symbol.Convolution(
    data=${2}, num_filter=${3:96}, kernel=(${4:7}, $4), pad=(${5:3},$5), stride=(${6:2}, $6))
relu$1 = mx.symbol.Activation(data=conv$1, act_type="relu")
endsnippet
snippet pool
pool${1:1} = mx.symbol.Pooling(data=${2}, pool_type="max", kernel=(${3:3}, $3), stride=(${4:2},$4))
endsnippet
snippet lrn
lrn${1:1} = mx.symbol.LRN(data=${2}, nsize=3, alpha=0.0005, beta=0.75, knorm=1)
endsnippet

# tensorflow
snippet place
tf.placeholder(tf.float32, [${1}])
endsnippet
snippet var
tf.Variable(${1})
endsnippet
snippet conv
${1} = tf.nn.conv2d(x, W, strides=[1, ${2:stride}, $2, 1], padding='SAME')
endsnippet
snippet pool
${1} = tf.nn.max_pool(x, ksize=[1, ${2:size}, $2, 1], strides=[1,$2, $2, 1], padding='SAME')
endsnippet
snippet bias
tf.nn.bias_add(${1})
endsnippet
snippet relu
tf.nn.relu(${1})
endsnippet
snippet drop
tf.nn.dropout(${1}, dropout)
endsnippet
snippet cross
tf.nn.softmax_cross_entropy_with_logits(${1:model_y}, ${2:y})
endsnippet
snippet add
tf.add(${1})
endsnippet
snippet mul
tf.matmul(${1})
endsnippet
snippet rand
tf.random_normal([${1:h}, ${2:w}, ${3:in}, ${4:out}])
endsnippet
snippet mean
tf.reduce_mean(${1})
endsnippet
snippet cast
tf.cast(${1}, ${2:tf.float32})
endsnippet
snippet equal
tf.equal(${1})
endsnippet
snippet argmax
tf.argmax(${1}, ${2:dimension})
endsnippet

snippet opti
tf.train.GradientDescentOptimizer(learning_rate=${1:learning_rate}).minimize(${2:cost_op})
endsnippet
snippet opti
tf.train.AdamOptimizer(learning_rate=${1:learning_rate}).minimize(${2:cost_op})
endsnippet

snippet runtrain
sess.run(train_op, feed_dict = {${1:x}:${2}, ${3:y}:${4}})
endsnippet
snippet runcost
sess.run(cost_op, feed_dict = {${1:x}:${2}, ${3:y}:${4}})
endsnippet
snippet runacc
sess.run(accuracy_op, feed_dict = {${1:x}:${2}, ${3:y}:${4}})
endsnippet

snippet train
#!/usr/bin/env python
# -*- coding: utf-8 -*-

import numpy as np
import tensorflow as tf

import sys, os
from objdect.config.config import cfg, cfg_from_file
from objdect.datasets import datasets
from objdect.networks import fasterRCNN
from objdect.utils.timer import Timer
from objdect.train.roi_data_layer.layer import RoIDataLayer 
from objdect.train.prepare_roidb import get_training_roidb
from objdect.train.loss import loss
from objdect.train.evaluate import evaluate_net

import pdb

# parameters
cfg_from_file(os.path.join(this_dir, 'config.yml'))


# data (dsX, dsY)
dataset_path = os.path.join(os.environ['HOME'], '${1:data/VOCdevkit}')
imdb_name = 'voc_2007_trainval'
imdb = datasets.get_imdb(imdb_name, dataset_path)
n_classes = 21


# data-preprocess
roidb = get_training_roidb(imdb)


## model
basenet_name = 'vgg16'
pretrained_model = os.path.join('${2:/home/duino/project/objdect/data}/pretrain_model/VGG_imagenet.npy')
net = fasterRCNN.get_network(basenet_name, n_classes, 'train')


# cost
loss, cross_entropy, loss_box, rpn_cross_entropy, rpn_loss_box = loss.build_loss()


# optimizer
if cfg.TRAIN.SOLVER == 'Adam':
    opt = tf.train.AdamOptimizer(cfg.TRAIN.lr)
elif cfg.TRAIN.SOLVER == 'RMS':
    opt = tf.train.RMSPropOptimizer(cfg.TRAIN.lr)
elif cfg.TRAIN.solver = 'MOM':
    lr = tf.Variable(cfg.TRAIN.lr, trainable=False)
    opt = tf.train.MomentumOptimizer(cfg.TRAIN.lr, cfg.TRAIN.momentum)
else:
    raise NotImplementedError
train_op = opt.minimize(loss)


# summary
tf.summary.scalar('rpn_box_loss', rpn_loss_box)
tf.summary.scalar('rpn_cls_loss', rpn_cross_entropy)
tf.summary.scalar('box_loss', loss_box)
tf.summary.scalar('cls_loss', cross_entropy)
tf.summary.scalar('loss', loss)
summary_op = tf.summary.merge_all()


# train
with tf.Session() as sess:
    sess.run(tf.global_variables_initializer())
	restore_iter = 0

    ## load_pretrained_model
    if pretrained_model is not None and not cfg.TRAIN.restore:
        try:
            print ('Loading pretrained model weights from {:s}'.format(pretrained_model))
            net.load(pretrained_model, sess, ignore_missing=True)
        except:
            raise 'Check your pretrained model {:s}'.format(pretrained_model)

    if cfg.TRAIN.restore:
        try:
            ckpt = tf.train.get_checkpoint_state(cfg.TRAIN.output_dir)
            print 'Restoring from {}...'.format(ckpt.model_checkpoint_path),
            self.saver.restore(sess, ckpt.model_checkpoint_path)
            stem = os.path.splitext(os.path.basename(ckpt.model_checkpoint_path))[0]
            restore_iter = int(stem.split('_')[-1])
            sess.run(global_step.assign(restore_iter))
            print 'done'
        except:
            raise 'Check your pretrained {:s}'.format(ckpt.model_checkpoint_path)

    ## train
    last_snapshot_iter = -1
    timer = Timer()
    for iter in range(restore_iter, cfg.TRAIN.max_iters):
        timer.tic()
        
		# adjust learning rate if using MomentumOptimizer
        if iter != 0 and iter % cfg.TRAIN.stepsize == 0:
            sess.run(tf.assign(lr, lr.eval() * cfg.TRAIN.gamma))

        # get one batch
        data_layer = RoIDataLayer(roidb, imdb.num_classes)
        blobs = data_layer.forward()
        if (iter + 1) % (cfg.TRAIN.DISPLAY) == 0:
            print 'image: %s' %(blobs['im_name']),

        feed_dict = {
            net.data: blobs['data'],
            net.im_info: blobs['im_info'],
            net.keep_prob: 0.5,
            net.gt_boxes: blobs['gt_boxes'],
            net.gt_ishard: blobs['gt_ishard'],
            net.dontcare_areas: blobs['dontcare_areas']
        }
        res_fetches = [
            net.get_output('cls_prob'),
            net.get_output('bbox_pred'),
            net.get_output('rois')
        ]
        fetch_list = [rpn_cross_entropy,
                      rpn_loss_box,
                      train_op] + res_fetches
        fetch_list += []

        # train
        rpn_loss_cls_value, rpn_loss_box_value, loss_cls_value, loss_box_value, _, cls_prob, bbox_pred, rois = sess.run(fetches=fetch_list, feed_dict=feed_dict)

        _diff_time = timer.toc()

        if (iter) % (cfg.TRAIN.DISPLAY) == 0:
            print 'iter: %d / %d, rpn_loss_cls: %.4f, rpn_loss_box: %.4f, loss_cls: %.4f, loss_box: %.4f, lr: %f'%(iter, max_iters, rpn_loss_cls_value, rpn_loss_box_value, loss_cls_value, loss_box_value, learning_rate)
            print 'speed: {:.3f}s / iter'.format(_diff_time)

        if (iter+1) % cfg.TRAIN.SNAPSHOT_ITERS == 0:
            last_snapshot_iter = iter
            self.snapshot(sess, iter)

# evaluate
with tf.Session() as sess:
    sess.run(tf.global_variables_initializer())
    evaluate_net(sess, net, imdb)
endsnippet

# machine learning
snippet ml
import numpy as np
import tensorflow as tf
from sklearn.utils import shuffle

# parameters
learning_rate = 0.05
epoches = 1000
print_period = 10
print_en = True

# data (dsX, dsY)

# data-preprocess

# model

# cost

# optimizer

# train

endsnippet
