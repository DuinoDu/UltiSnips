snippet tool
#!/usr/bin/env python
# -*- coding: utf-8 -*-

'''
python ${1:yourFunction}.py ${2:args}
'''
import os, sys

def $1(argv):
	${3:pass}

def main():
    import sys
	if len(sys.argv) != 2:
		print(__doc__)
		return
    $1(sys.argv)

if __name__ == "__main__":
	main()
endsnippet

snippet isdir
if not os.path.exists(${1:dirname}):
    os.makedirs($1)
endsnippet

snippet dump
with open('${2:file}', 'w') as fid:
	cPickle.dump(${1:var}, fid)
endsnippet
snippet load
with open('${1:file}', 'r') as fid:
	${2:var} = cPickle.load(fid)
endsnippet

snippet readxml
#import xml.etree.ElementTree as ET
tree = ET.parse(xmlfile)
width = int(tree.find('size').find('width').text)
height = int(tree.find('size').find('height').text)
objs = tree.findall('object')
for index, obj in enumerate(objs):
    name = obj.find('name').text.lower()
    bbox = obj.find('bndbox')
    x1 = int(bbox.find('xmin').text) - 1
    y1 = int(bbox.find('ymin').text) - 1
    x2 = int(bbox.find('xmax').text) - 1
    y2 = int(bbox.find('ymax').text) - 1
endsnippet

snippet sh
cmd = '$1'
(status, output) = commands.getstatusoutput(cmd)
output = output.split('\n')
endsnippet

snippet getimg
${1:imgfiles} = sorted([os.path.join(${2:root}, x) for x in sorted(os.listdir($2)) if x.endswith('.jpg')])
endsnippet

snippet printi
    sys.stdout.flush()
    sys.stdout.write('writing {}/{}\r'.format(i, len(files)))
    i += 1 # set i = 0 before looping
print '\nFinish!'
endsnippet

snippet print
print($1)
endsnippet


snippet prop
@property
def ${1:name}(self):
    return self._$1
endsnippet

snippet camera
cap = cv2.VideoCapture(0)
while True:
    ok, f = cap.read()
    if ok:    
        cv2.imshow("image", f)
    if cv2.waitKey(20) == 27:
        break
cv2.destroyAllWindows()
endsnippet

snippet esc
ch = cv2.waitKey(0) & 0xff
if ch == 27: #ord('q')
	break
endsnippet

snippet cv2rect
cv2.rectangle(${1:img}, (${2:x1}, ${3:y1}), (${4:x2}, ${5:y2}), (0, 255, 0), 2)
endsnippet
snippet cv2circle
cv2.circle(${1:img}, (${2:x0}, ${3:y0}), ${4:r}, (0, 255, 0), 2)
endsnippet
snippet cv2resize
cv2.resize(${1:img}, ($1.shape[1]/${2}, $1.shape[0]/$2))
endsnippet

snippet contour
im = cv2.imread(${1:imgpath})
im_gray = cv2.cvtColor(im, cv2.COLOR_BGR2GRAY)
_, im_thresh = cv2.threshold(im_gray, 177, 255, cv2.THRESH_BINARY)
_, contours, hierarchy = cv2.findContours(im_thresh, cv2.RETR_TREE ,cv2.CHAIN_APPROX_SIMPLE)
cv2.drawContours(im, contours,-1,(0,255,0),1)
endsnippet


#########
# mxnet #
#########
snippet conv
conv${1:1} = mx.symbol.Convolution(
    data=${2}, num_filter=${3:96}, kernel=(${4:7}, $4), pad=(${5:3},$5), stride=(${6:2}, $6))
relu$1 = mx.symbol.Activation(data=conv$1, act_type="relu")
endsnippet
snippet pool
pool${1:1} = mx.symbol.Pooling(data=${2}, pool_type="max", kernel=(${3:3}, $3), stride=(${4:2},$4))
endsnippet
snippet lrn
lrn${1:1} = mx.symbol.LRN(data=${2}, nsize=3, alpha=0.0005, beta=0.75, knorm=1)
endsnippet

##############
# tensorflow #
##############
snippet place
tf.placeholder(tf.float32, shape=[${1}], name='${2}')
endsnippet
snippet var
tf.Variable(${1})
endsnippet
snippet conv
${1} = tf.nn.conv2d(x, W, strides=[1, ${2:stride}, $2, 1], padding='SAME')
endsnippet
snippet pool
${1} = tf.nn.max_pool(x, ksize=[1, ${2:size}, $2, 1], strides=[1,$2, $2, 1], padding='SAME')
endsnippet
snippet bias
tf.nn.bias_add(${1})
endsnippet
snippet relu
tf.nn.relu(${1})
endsnippet
snippet drop
tf.nn.dropout(${1}, dropout)
endsnippet
snippet cross
tf.nn.softmax_cross_entropy_with_logits(${1:model_y}, ${2:y})
endsnippet
snippet add
tf.add(${1})
endsnippet
snippet mul
tf.matmul(${1})
endsnippet
snippet rand
tf.random_normal([${1:h}, ${2:w}, ${3:in}, ${4:out}])
endsnippet
snippet mean
tf.reduce_mean(${1})
endsnippet
snippet cast
tf.cast(${1}, ${2:tf.float32})
endsnippet
snippet equal
tf.equal(${1})
endsnippet
snippet argmax
tf.argmax(${1}, ${2:dimension})
endsnippet

snippet opti
tf.train.GradientDescentOptimizer(learning_rate=${1:learning_rate}).minimize(${2:cost_op})
endsnippet
snippet opti
tf.train.AdamOptimizer(learning_rate=${1:learning_rate}).minimize(${2:cost_op})
endsnippet

snippet runtrain
sess.run(train_op, feed_dict = {${1:x}:${2}, ${3:y}:${4}})
endsnippet
snippet runcost
sess.run(cost_op, feed_dict = {${1:x}:${2}, ${3:y}:${4}})
endsnippet
snippet runacc
sess.run(accuracy_op, feed_dict = {${1:x}:${2}, ${3:y}:${4}})
endsnippet

snippet gpusize
config = tf.ConfigProto()
config.gpu_options.per_process_gpu_memory_fraction = ${1:0.5}
#with tf.Session(config=config) as sess:
endsnippet

snippet model
from .network import Network
from .basenet import basenet
import tensorflow as tf

def get_network(basenet_type, n_classes, phase):
    if phase == 'train':
        return $1_train(basenet_type, n_classes)
    elif phase == 'test':
        return $1_test(basenet_type, n_classes)
    else:
        raise 'Undefined phase: {}'.format(phase)

class ${1:net_name}_train(Network):
    def __init__(self, basenet_type, n_classes, trainable=True):
        self.inputs = []
        self.data = tf.placeholder(tf.float32, shape=[None, None, None, 3], name='data')
        self.im_info = tf.placeholder(tf.float32, shape=[None, 3], name='im_info')
        self.keep_prob = tf.placeholder(tf.float32)

        self.gt_boxes = tf.placeholder(tf.float32, shape=[None, 5], name='gt_boxes')
        self.gt_ishard = tf.placeholder(tf.float32, shape=[None], name='gt_ishard')
        self.dontcare_areas = tf.placeholder(tf.float32, shape=[None, 4], name='dontcare_areas')

        self.layers = dict({'data':self.data, 'im_info':self.im_info, 'gt_boxes':self.gt_boxes, 'gt_ishard':self.gt_ishard, 'dontcare_areas':self.dontcare_areas})
        self.trainable = trainable
        self.n_classes = n_classes
        self.basenet = basenet.get_net(basenet_type)

        self.setup()
    
    def setup(self):
        self = test_part(self, 'TRAIN')

		# TODO, training part

class $1_test(Network):
    def __init__(self, basenet_type, n_classes, trainable=True):
        self.inputs = []
        self.data = tf.placeholder(tf.float32, shape=[None, None, None, 3], name='data')
        self.im_info = tf.placeholder(tf.float32, shape=[None, 3], name='im_info')
        self.keep_prob = tf.placeholder(tf.float32)

        self.layers = dict({'data':self.data, 'im_info':self.im_info})
        self.trainable = trainable
        self.n_classes = n_classes
        self.basenet = basenet.get_net(basenet_type)

        self.setup()
    
    def setup(self):
		self.test_part(self, 'TEST')


def test_part(net, phase):
	# TODO, test part

    return net
endsnippet


snippet train
#!/usr/bin/env python
# -*- coding: utf-8 -*-

import numpy as np
import tensorflow as tf

import sys, os
from objdect.config.config import cfg, cfg_from_file
from objdect.datasets import datasets
from objdect.networks import fasterRCNN
from objdect.utils.timer import Timer
from objdect.train.roi_data_layer.layer import RoIDataLayer 
from objdect.train.prepare_roidb import get_training_roidb
from objdect.train.loss import loss
from objdect.train.evaluate import evaluate_net

import pdb

# parameters
cfg_from_file(os.path.join(this_dir, 'config.yml'))


# data (dsX, dsY)
dataset_path = os.path.join(os.environ['HOME'], '${1:data/VOCdevkit}')
imdb_name = 'voc_2007_trainval'
imdb = datasets.get_imdb(imdb_name, dataset_path)
n_classes = 21


# data-preprocess
roidb = get_training_roidb(imdb)


## model
basenet_name = 'vgg16'
pretrained_model = os.path.join('${2:/home/duino/project/objdect/data}/pretrain_model/VGG_imagenet.npy')
net = fasterRCNN.get_network(basenet_name, n_classes, 'train')


# cost
loss, cross_entropy, loss_box, rpn_cross_entropy, rpn_loss_box = loss.build_loss(net)


# optimizer
if cfg.TRAIN.SOLVER == 'Adam':
    opt = tf.train.AdamOptimizer(cfg.TRAIN.lr)
elif cfg.TRAIN.SOLVER == 'RMS':
    opt = tf.train.RMSPropOptimizer(cfg.TRAIN.lr)
elif cfg.TRAIN.solver == 'MOM':
    lr = tf.Variable(cfg.TRAIN.lr, trainable=False)
    opt = tf.train.MomentumOptimizer(cfg.TRAIN.lr, cfg.TRAIN.momentum)
else:
    raise NotImplementedError
train_op = opt.minimize(loss)


# summary
tf.summary.scalar('rpn_box_loss', rpn_loss_box)
tf.summary.scalar('rpn_cls_loss', rpn_cross_entropy)
tf.summary.scalar('box_loss', loss_box)
tf.summary.scalar('cls_loss', cross_entropy)
tf.summary.scalar('loss', loss)
summary_op = tf.summary.merge_all()


# train
with tf.Session() as sess:
    sess.run(tf.global_variables_initializer())
	restore_iter = 0

    ## load_pretrained_model
    if pretrained_model is not None and not cfg.TRAIN.restore:
        try:
            print ('Loading pretrained model weights from {:s}'.format(pretrained_model))
            net.load(pretrained_model, sess, ignore_missing=True)
        except:
            raise 'Check your pretrained model {:s}'.format(pretrained_model)

    if cfg.TRAIN.restore:
        try:
            ckpt = tf.train.get_checkpoint_state(cfg.TRAIN.output_dir)
            print 'Restoring from {}...'.format(ckpt.model_checkpoint_path),
            self.saver.restore(sess, ckpt.model_checkpoint_path)
            stem = os.path.splitext(os.path.basename(ckpt.model_checkpoint_path))[0]
            restore_iter = int(stem.split('_')[-1])
            sess.run(global_step.assign(restore_iter))
            print 'done'
        except:
            raise 'Check your pretrained {:s}'.format(ckpt.model_checkpoint_path)

    ## train
    last_snapshot_iter = -1
    timer = Timer()
    for iter in range(restore_iter, cfg.TRAIN.max_iters):
        timer.tic()
        
		# adjust learning rate if using MomentumOptimizer
        if iter != 0 and iter % cfg.TRAIN.stepsize == 0:
            sess.run(tf.assign(lr, lr.eval() * cfg.TRAIN.gamma))

        # get one batch
        data_layer = RoIDataLayer(roidb, imdb.num_classes)
        blobs = data_layer.forward()
        if (iter + 1) % (cfg.TRAIN.DISPLAY) == 0:
            print 'image: %s' %(blobs['im_name']),

        feed_dict = {
            net.data: blobs['data'],
            net.im_info: blobs['im_info'],
            net.keep_prob: 0.5,
            net.gt_boxes: blobs['gt_boxes'],
            net.gt_ishard: blobs['gt_ishard'],
            net.dontcare_areas: blobs['dontcare_areas']
        }
        res_fetches = [
            net.get_output('cls_prob'),
            net.get_output('bbox_pred'),
            net.get_output('rois')
        ]
        fetch_list = [rpn_cross_entropy,
                      rpn_loss_box,
                      train_op] + res_fetches
        fetch_list += []

        # train
        rpn_loss_cls_value, rpn_loss_box_value, loss_cls_value, loss_box_value, _, cls_prob, bbox_pred, rois = sess.run(fetches=fetch_list, feed_dict=feed_dict)

        _diff_time = timer.toc()

        if (iter) % (cfg.TRAIN.DISPLAY) == 0:
            print 'iter: %d / %d, rpn_loss_cls: %.4f, rpn_loss_box: %.4f, loss_cls: %.4f, loss_box: %.4f, lr: %f'%(iter, max_iters, rpn_loss_cls_value, rpn_loss_box_value, loss_cls_value, loss_box_value, learning_rate)
            print 'speed: {:.3f}s / iter'.format(_diff_time)

        if (iter+1) % cfg.TRAIN.SNAPSHOT_ITERS == 0:
            last_snapshot_iter = iter
            self.snapshot(sess, iter)

# evaluate
with tf.Session() as sess:
    sess.run(tf.global_variables_initializer())
    evaluate_net(sess, net, imdb)
endsnippet

# machine learning
snippet ml
import numpy as np
import tensorflow as tf
from sklearn.utils import shuffle

# parameters
learning_rate = 0.05
epoches = 1000
print_period = 10
print_en = True

# data (dsX, dsY)

# data-preprocess

# model

# cost

# optimizer

# train

endsnippet

snippet tic
t1 = time.time()
${1:add your function}
t2 = time.time()    
print "${2:msg to display}: {}".format(t2-t1)
endsnippet
