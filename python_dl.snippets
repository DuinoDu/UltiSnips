####################################
#
# numpy
#
####################################
snippet tohwc
${1:ndarray} = np.transpose(${2:ndarray}, (1,2,0))
endsnippet

snippet tochw
${1:ndarray} = np.transpose(${2:ndarray}, (2,0,1))
endsnippet

snippet npconcat
np.concatenate((${1:a}, ${2:b}), axis=${3:0})
endsnippet

snippet npunsqu
${1:a}[np.newaxis, :]
#np.expand_dims(${1:a}, axis=${2:0})
endsnippet

snippet totensor
${1:tensor} = torch.from_numpy(${2:ndarray}.transpose((2, 0, 1))).float().div(255)
endsnippet

snippet tonumpy
${1:ndarray} = torch.cpu().numpy(${2:tensor})
endsnippet

snippet shownp
from PIL import Image
Image.fromarray(${1:arr}).show()
endsnippet

snippet savepil
from PIL import Image
Image.fromarray(${1:arr}).save(${2:filename})
endsnippet

####################################
#
# matplotlib
#
####################################
snippet hist
import matplotlib.pyplot as plt

plt.hist(${1:data_list}, ${2:bins})
plt.show()
endsnippet


####################################
#
# common
#
####################################
snippet initarg
import argparse
parser = argparse.ArgumentParser(description='${1:description of this script}')
args = parser.parse_args()
endsnippet

snippet addarg
parser.add_argument('--${1:name}', default=${2}, type=${3:str}, help='${4:description}')
endsnippet

snippet addact
parser.add_argument('--${1:name}', dest='$1', action='store_${2:true}', help='${3:description}')
endsnippet

snippet initcfg
from easydict import EasyDict as edict
import os

HOME = os.path.expanduser("~")
cfg = edict()

# dataset
cfg.root = os.path.join(HOME, "data/VOCdevkit/")
cfg.num_classes = 21

# model
cfg.means = (104, 117, 123)

# loss

# optimizer
cfg.lr =  
cfg.momentum = 
cfg.weight_decay = 
cfg.gamma =
cfg.start_epoch = 
cfg.num_epochs = 
cfg.batch_size = 

# test

# others
cfg.cuda = True
cfg.gpuID = '1'
cfg.num_workers = 2
cfg.resume = None
cfg.tensorboard = False
cfg.save_folder = 'output'
cfg.weight_prefix = 'ssd300_0712_'
cfg.final_name = 'ssd300_voc_final.pth'
cfg.eval_on_epoch = 10
cfg.save_on_epoch = 10
endsnippet


####################################
#
# pytorch
#
####################################

snippet inctorch
import torch
import torch.nn as nn
import torch.nn.init as init
import torch.backends.cudnn as cudnn
endsnippet

snippet setgpu
parser.add_argument('--cuda', default=1, type=int, help='if using cuda')
parser.add_argument('--gpuID', default=0, type=int, help='Use which gpu to train model')
import os
os.environ['CUDA_VISIBLE_DIVICES'] = str(args.gpuID)
device = torch.device('cuda' if args.cuda else 'cpu')
endsnippet

snippet multigpu
${1:net} = nn.DataParallel($1).cuda()
endsnippet

snippet torch_dataset
class AnnotationTransform(object):
    """
    Load annotation from file to loss input
    """
    def __init__(self):
        pass


    def __call__(self, target):
        res = []
        return res 


class ${1:Name}(data.Dataset):
    """
    TODO
    """
    def __init__(self, root, phase, transform=None, target_transform=AnnotationTransform(),
                 dataset_name='$1'):
        self.root = cfg.root
        self.phase = phase
        self.transform = transform
        self.target_transform = target_transform
        self.name = dataset_name
        # TODO: set image and anno path
        #self._annopath = os.path.join('%s', 'Annotations', '%s.xml')
        #self._imgpath = os.path.join('%s', 'JPEGImages', '%s.jpg')
        #self.ids = list()
        #for (year, name) in image_sets:
        #    rootpath = os.path.join(self.root, 'VOC' + year)
        #    for line in open(os.path.join(rootpath, 'ImageSets', 'Main', name + '.txt')):
        #        self.ids.append((rootpath, line.strip()))


    def __len__(self):
        return len(self.ids)


    def __getitem__(self, index):
        # TODO
        return im, gt


def custom_collate(batch):
    """Custom collate fn for dealing with batches of images that have a different
    number of associated object annotations (bounding boxes).

    [TODO]: use default collate if not need.
    """
    imgs = []
    targets = []
    # TODO
    return torch.stack(imgs, 0), targets


def make_dataloader(cfg, root, phase, augment):
    root = cfg.root
    batch_size = cfg.batch_size
    num_workers = cfg.num_workers
    shuffle = cfg.shuffle if phase == 'train' else False
    pin_memory = cfg.pin_memory

    dataset = $1(root, image_sets, augment, AnnotationTransform())
    return data.DataLoader(dataset, 
                           batch_size, 
                           num_workers=num_workers,
                           shuffle=shuffle, 
                           pin_memory=pin_memory,
                           collate_fn=custom_collate)
endsnippet

snippet compose
class ${1:name}Augmentation(object):
	def __init__(self, ${3:args}):
		self.transforms = [
				# TODO: add more
				ToTensor(),
				]
	def __call__(self, ${2:im}):
		for t in self.transforms:
			$2 = t($2)
		return $2
endsnippet

snippet tran
class ${1:name}(object):
    def __init__(self, ${2:args}):
		self.$2 = $2
		pass
    def __call__(self, im, ${3:args}):
		pass
endsnippet

snippet module
from detect import Detect
class ${1:name}(nn.Module):

    def __init__(self, cfg, phase):
        super($1, self).__init__()
		self.cfg = cfg
		self.phase = phase
		if self.phase == 'test':
			self.detect = Detect()
        # TODO: init module

    def forward(self, x):
        # TODO: build module

		if self.phase == 'train':
			return x
		else self.phase == 'test':
			return self.detect(x)
endsnippet

snippet testmodule
net = ${1:Model}(2)
x = torch.randn(1,3,1000,800)
pred = net(x)
print("input size: ", x.size())
print("output size:", pred.size())
endsnippet

snippet initweight
    self._init_weight()

def _init_weight(self):
    def weight_init(m):
        if isinstance(m, nn.Conv2d):
            init.${1:xavier_uniform}(m.weight.data)
            if m.bias is not None:
                m.bias.data.zero_()
        elif isinstance(m, nn.BatchNorm2d):
            m.weight.data.fill_(${2:1})
            if m.bias is not None:
                m.bias.data.zero_()
    self.apply(weight_init)
endsnippet

snippet loadweight
    if pretrain:
        self._load_weight()

from torchvision import models
import os, glob
def _load_weight(self, weight_file=None):
    source_dict = torch.load(weight_file)
    source_dict = target_dict 
    self.load_state_dict(target_dict)
    print('Loading weight successfully!')
endsnippet

snippet tconv
nn.Conv2d(${1:in_channels}, ${2:out_channels}, kernel_size=${3:3}, padding=${4:1})
endsnippet

snippet tbn
nn.BatchNorm2d(${1::in_channels})
endsnippet

snippet trelu
nn.ReLU()
endsnippet


####################################
#
# mxnet
#
####################################
snippet testsym
data = mx.sym.Variable(name='data')
data_shape = (1, 3, 256, 256)
data = mx.sym.Variable(name='data')
net_symbol = ${1:build_net}(data)
output_shape = net_symbol.infer_shape(data=data_shape)
print('network output shape:', output_shape[1])
endsnippet

snippet symconv 
${3:output} = mx.symbol.Convolution(name='${1:name}', data=${2:input}, num_filter=${4:64}, pad=(${5:1}, $5), 
                                    kernel=(${6:3}, $6), stride=(${7:1}, $7), no_bias=${8:True})
endsnippet

snippet symbn
${3:output} = mx.symbol.BatchNorm(name='${1:name}', data=${2:input}, use_global_stats=True, fix_gamma=False, 
                                  eps=${4:eps})
endsnippet

snippet symrelu
${3:output} = mx.symbol.Activation(name='${1:name}', data=${2:input}, act_type='relu')
endsnippet

snippet sympool
${3:output} = mx.symbol.Pooling(name='${1:name}', data=${2:input}, pooling_convention='full', 
                                pad=(${4:0}, $4), kernel=(${5:3}, $5), stride=(${6:2}, $6), pool_type='${7:max}')
endsnippet

snippet tosym
sym = ${1:net}(mx.sym.var('data'))
endsnippet

snippet mxviz
mx.viz.plot_network(symbol=${1:symbol}, shape={'data':${2:(1,3,224,224)}}, title='symbol', save_format='jpg').render()
endsnippet

snippet readrec
imgrec = mx.recordio.MXIndexedRecordIO(imgidx_path, imgrec_path, 'r')
_, img = mx.recordio.unpack_img(imgrec[roi_rec['imgrec_id']].read_idx(roi_rec['imgrec_idx']), cv2.IMREAD_COLOR)
endsnippet


####################################
#
# gluon
#
####################################
snippet incgluon
import mxnet as mx
import mxnet.ndarray as nd
import mxnet.gluon as gluon
import mxnet.gluon.nn as nn
import mxnet.autograd as autograd
endsnippet

snippet hs "gluon.nn.HybridSequential"
${1:out} = nn.HybridSequential(${2:**kwargs})
with $1.name_scope():
	$1.add($3)
endsnippet

snippet hs2 "gluon.nn.HybridSequential"
with self.name_scope():
	${1:out} = nn.HybridSequential()
	$1.add($2)
endsnippet

snippet hb "gluon.nn.HybridBlock"
class ${1:BlockName}(nn.HybridBlock):
	def __init__(self, ${2}, **kwargs):
		super($1, self).__init__(**kwargs)

	def hybrid_forward(self, F, x):
		${3:#TODO}
		return x
endsnippet

snippet testblock
x = nd.random_normal(shape=(${1:1, 3, 224, 224}))
net = ${2:Net}()
net.collect_params().initialize()
y = net(x)
print(y.shape)
endsnippet

snippet gconv
nn.Conv2D(${1:out_channels}, ${2:kernel_size}, strides=${3}, padding=${4:1}, use_bias=${5:False})
endsnippet

snippet gbn
nn.BatchNorm(scale=True)
endsnippet

snippet grelu
nn.Activation('${1:relu}')
endsnippet

####################################
#
# gluon_horizon
#
####################################
snippet checkmodel
from gluon_horizon.hbcc.utils import get_symbol
from gluon_horizon.hbcc.model_checker import model_checker
with QuantizationBlockScope(mode=QuantizationModeEnum.kIntInference, mirroring_level=0):
	net = ${1:Net()} 
symbol = get_symbol(net, num_inputs=1)
flag = model_checker(symbol, march='x2', shape=(1, ${2:28}, ${3:28}, 3), strip_quanti_op_postfix=True, remove_tmp_files=True)
if flag == 0:
	print('[+]Success to pass model checker![+]')
else:
	print('[-]Failed to pass model checker![-]')

endsnippet


####################################
#
# hobotpy
#
####################################
snippet transform
class ${1:Name}TrainTransform(object):
	"""Default training transform for $1.
	Parameters
	----------
	"""
	def __init__(self, **kwargs):
		pass

	def __call__(self, src, label, img_path):
		pass
		return img, label, img_path


class $1ValTransform(object):
	"""Default valid transform for $1.
	Parameters
	----------
	"""
	def __init__(self, **kwargs):
		pass

	def __call__(self, src, label, img_path):
		pass
	return img, label, img_path
endsnippet
